{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6474277e-4a5a-44cd-8808-dbd0df5de211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "# clear_output(wait=True)\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "# mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d432bc99-8e6e-44ce-b154-d7f02426f086",
   "metadata": {},
   "source": [
    "## 촬영"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a2c908ce-a55d-49f4-be1d-3721b6cc776b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('http://192.168.0.9:81/stream')\n",
    "while True:\n",
    "    success, image = cap.read()\n",
    "    cv2.imshow('MediaPipe Hands', image)\n",
    "    if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a05d5da-8fce-4912-a67a-d960bbb1df6e",
   "metadata": {},
   "source": [
    "## 손 인식해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "707cfb8e-9054-409e-b7e4-f7cedacf45f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: 0.5884106755256653\n",
      "y: 0.5645489692687988\n",
      "z: -0.2368655651807785\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For webcam input:\n",
    "# cap = cv2.VideoCapture(2)\n",
    "# cap = cv2.VideoCapture('http://192.168.0.9:81/stream')\n",
    "cap = cv2.VideoCapture('http://192.168.0.8:8080/video')\n",
    "\n",
    "with mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            # If loading a video, use 'break' instead of 'continue'.\n",
    "            break\n",
    "\n",
    "        # Flip the image horizontally for a later selfie-view display, and convert\n",
    "        # the BGR image to RGB.\n",
    "        image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        # To improve performance, optionally mark the image as not writeable to\n",
    "        # pass by reference.\n",
    "        image.flags.writeable = False\n",
    "        results = hands.process(image)\n",
    "\n",
    "        # Draw the hand annotations on the image.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS,)\n",
    "#                     mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "#                     mp_drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "                clear_output(wait=True)\n",
    "                print(hand_landmarks.landmark[8])\n",
    "        \n",
    "        cv2.imshow('MediaPipe Hands', image)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "cv2.destroyAllWindows()   \n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12538cca-280e-4363-ac8f-936dfb02799b",
   "metadata": {},
   "source": [
    "## tap, release 인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "586f96c3-f7c1-4685-ab02-ac3e56848a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right\n",
      "0.639749420369165\n",
      "0.5361245793151832\n",
      "0.36179965316615764\n",
      "0.2886007744645433\n",
      "Realse 0\n",
      "Realse 1\n",
      "Realse 2\n",
      "Tap 3\n"
     ]
    }
   ],
   "source": [
    "def img_process(image):\n",
    "    image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = hands.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    return image, results\n",
    "\n",
    "def to_numpy(landmark):\n",
    "    return np.array([landmark.x, landmark.y, landmark.z])\n",
    "\n",
    "def get_std_len(hand_landmarks):\n",
    "    mark1 = to_numpy(hand_landmarks.landmark[0])\n",
    "    mark2 = to_numpy(hand_landmarks.landmark[5])\n",
    "    std_len = np.linalg.norm(mark1-mark2)\n",
    "    return std_len\n",
    "\n",
    "\n",
    "# left_release = [True] * 4\n",
    "# right_release = [True] * 4\n",
    "flags = [True] * 4\n",
    "\n",
    "# For webcam input:\n",
    "# cap = cv2.VideoCapture(2)\n",
    "# cap = cv2.VideoCapture('http://192.168.0.9:81/stream')\n",
    "cap = cv2.VideoCapture('http://192.168.0.8:8080/video')\n",
    "with mp_hands.Hands(max_num_hands=2, min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            # If loading a video, use 'break' instead of 'continue'.\n",
    "            break\n",
    "            \n",
    "        image, results = img_process(image)\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            clear_output(wait=True)\n",
    "            print(results.multi_handedness[0].classification[0].label)\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS,)\n",
    "                \n",
    "                \n",
    "                marks = [0, 5, 9, 13, 17, 4, 8, 12, 16, 20]\n",
    "                locs = np.stack([to_numpy(hand_landmarks.landmark[i]) for i in marks])\n",
    "                std_len = np.linalg.norm(locs[0] - locs[1])\n",
    "                \n",
    "                dists = np.linalg.norm(locs[5] - locs[6:], axis=1) / std_len\n",
    "                \n",
    "                \n",
    "#                 print(dists)\n",
    "    \n",
    "                for i in range(4):\n",
    "                    print(dists[i])\n",
    "                    if flags[i] and dists[i] < 0.35:\n",
    "                        flags[i] = False\n",
    "                    elif not flags[i] and 0.5 < dists[i]:\n",
    "                        flags[i] = True\n",
    "                        \n",
    "                for i in range(4):\n",
    "                    if flags[i]:\n",
    "                        print('Realse %d'%i)\n",
    "                    else :\n",
    "                        print('Tap %d'%i)\n",
    "                \n",
    "                \n",
    "#                     mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "#                     mp_drawing_styles.get_default_hand_connections_style())\n",
    "        cv2.imshow('MediaPipe Hands', image)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "cv2.destroyAllWindows()   \n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0eb7ba3-f0be-4b4e-9f6b-6ada80518a08",
   "metadata": {},
   "source": [
    "## 각도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b5c03a2-310d-454d-b1b8-5d1261717a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(landmark):\n",
    "    return np.array([landmark.x, landmark.y, landmark.z])\n",
    "\n",
    "# left_release = [True] * 4\n",
    "# right_release = [True] * 4\n",
    "flags = [True] * 4\n",
    "\n",
    "# For webcam input:\n",
    "# cap = cv2.VideoCapture(2)\n",
    "# cap = cv2.VideoCapture('http://192.168.0.9:81/stream')\n",
    "cap = cv2.VideoCapture('http://192.168.0.8:8080/video')\n",
    "with mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            # If loading a video, use 'break' instead of 'continue'.\n",
    "            break\n",
    "\n",
    "        # Flip the image horizontally for a later selfie-view display, and convert\n",
    "        # the BGR image to RGB.\n",
    "        image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        # To improve performance, optionally mark the image as not writeable to\n",
    "        # pass by reference.\n",
    "        image.flags.writeable = False\n",
    "        results = hands.process(image)\n",
    "\n",
    "        # Draw the hand annotations on the image.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS,)\n",
    "                \n",
    "                marks = [0, 5, 9, 13, 17, 4, 8, 12, 16, 20]\n",
    "                locs = np.stack([to_numpy(hand_landmarks.landmark[i]) for i in marks])\n",
    "                \n",
    "                vector1 = locs[0] - locs[1:5] # wrist_to_middle\n",
    "                vector2 =  locs[6:] - locs[1:5] # middle_to_edge\n",
    "                len_vector1 = np.linalg.norm(vector1, axis=1).reshape(-1,1)\n",
    "                len_vector2 = np.linalg.norm(vector2, axis=1).reshape(-1,1)\n",
    "                # normalize\n",
    "                vector1 = vector1 / len_vector1\n",
    "                vector2 = vector2 / len_vector2\n",
    "                \n",
    "                # 내적공식 A·B = xx`+ yy`+ zz` = |A|*|B|*cos(Θ)\n",
    "                cos_val = np.einsum('nt,nt->n', vector1, vector2)\n",
    "                angle = np.rad2deg(np.arccos(cos_val))\n",
    "                \n",
    "                clear_output(wait=True)\n",
    "                for v in angle:\n",
    "                    print(v)\n",
    "                \n",
    "                \n",
    "#                 dists = np.linalg.norm(locs[5] - locs[6:], axis=1) / std_len\n",
    "                \n",
    "#                 print(dists)\n",
    "#                 for i in range(4):\n",
    "#                     if flags[i] and dists[i] < 0.35:\n",
    "#                         flags[i] = False\n",
    "# #                         print('Tap %d'%i, dists[i])\n",
    "#                     if not flags[i] and 0.45 < dists[i]:\n",
    "#                         flags[i] = True\n",
    "# #                         print('Realse %d'%i, dists[i])\n",
    "#                     if flags[i]:\n",
    "#                         print('Realse %d'%i)\n",
    "#                     else :\n",
    "#                         print('Tap %d'%i)\n",
    "                \n",
    "                \n",
    "        cv2.imshow('MediaPipe Hands', image)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "cv2.destroyAllWindows()   \n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b657a86a-702d-4886-ba13-03f144523f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((237, 22), 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.getTextSize('Happy Coding', cv2.FONT_HERSHEY_COMPLEX, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17feebcb-a56e-4527-9518-c51d856d8ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH, HEIGHT = 1280, 720\n",
    "\n",
    "def xyxy_to_xywh(xyxy):\n",
    "    center = (xyxy[2:] + xyxy[:2])//2\n",
    "    wh = xyxy[2:] - xyxy[:2]\n",
    "    return np.concatenate([center, wh], axis=-1)\n",
    "\n",
    "def xywh_to_xyxy(xywh):\n",
    "    xy1 = xywh[:2] - xywh[2:]//2\n",
    "    xy2 = xywh[:2] + xywh[2:]//2\n",
    "    return np.concatenate([xy1, xy2], axis=-1)\n",
    "\n",
    "def draw_text(img, text, box_xywh):\n",
    "    text_size = np.array(cv2.getTextSize(text, cv2.FONT_HERSHEY_COMPLEX, 1, 2)[0])\n",
    "    text_size[1] *= -1\n",
    "    text_xy1 = box_xywh[:2] - text_size//2\n",
    "#     text_xy2 = box_xywh[:2] + text_size//2\n",
    "#     cv2.rectangle(img, text_xy1, text_xy2, (255,0,0), -1)\n",
    "    cv2.putText(img, text, text_xy1, cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 0), 2, cv2.LINE_AA, )\n",
    "    \n",
    "class BoxObject():\n",
    "    def __init__(self, xywh, color=(0, 0, 255), text='', editable=False):\n",
    "        self.xywh = np.array(xywh)\n",
    "        self.color = color\n",
    "        self.text = text\n",
    "        self.editable = editable\n",
    "        \n",
    "    def draw(self, img):\n",
    "        xyxy = xywh_to_xyxy(self.xywh)\n",
    "        cv2.rectangle(img, xyxy[:2], xyxy[2:], self.color, -1)\n",
    "        draw_text(img, self.text, self.xywh)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str((self.text, 'edit:%s'%self.editable))\n",
    "    \n",
    "class HandManager():\n",
    "    def __init__(self, label):\n",
    "        self.label = label\n",
    "        self.locs = [None]*21\n",
    "        self.std_len = None\n",
    "        self.dists = None\n",
    "        self.state = [0]*4 # 0-release, 1-click, 2-drag\n",
    "        \n",
    "    def update(self, marks):\n",
    "        locs = np.stack([to_numpy(mark) for mark in marks])\n",
    "        locs = np.clip(locs, 0, 1)\n",
    "        locs[:,0] *= WIDTH-1\n",
    "        locs[:,1] *= HEIGHT-1\n",
    "        self.locs = locs.astype(np.int32)\n",
    "        self.std_len = np.linalg.norm(locs[0] - locs[5])\n",
    "        self.dists = np.linalg.norm(locs[4] - locs[[8,12,16,20]], axis=1) / self.std_len\n",
    "\n",
    "        for i in range(4):\n",
    "            if not self.state[i] and self.dists[i] < 0.35: self.state[i] = 1\n",
    "            elif self.state[i] and 0.45 < self.dists[i]: self.state[i] = 0\n",
    "            elif self.state[i] == 1: self.state[i] = 2\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return '#####\\nlabel : {}\\n검지위치 : {}\\ndists : {}\\nstate : {}'.format(self.label, self.locs[8], self.dists, self.state)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3dc7f56f-8320-4b57-b2f6-b6c151032f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "click mode\n",
      "#####\n",
      "label : Right\n",
      "검지위치 : [169  36]\n",
      "dists : [0.83508914 0.66246122 0.53304543 0.30878388]\n",
      "state : [0, 0, 0, 1]\n",
      "graped_box: None\n",
      "selected_box: None\n"
     ]
    }
   ],
   "source": [
    "def img_process(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = hands.process(image)\n",
    "#     image.flags.writeable = True\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return results\n",
    "#     return image, results\n",
    "\n",
    "def to_numpy(landmark):\n",
    "    return np.array([landmark.x, landmark.y])\n",
    "\n",
    "# def get_locs(marks):\n",
    "#     locs = np.stack([to_numpy(mark) for mark in marks])\n",
    "#     locs = np.clip(locs, 0, 1)\n",
    "#     locs[:,0] *= WIDTH-1\n",
    "#     locs[:,1] *= HEIGHT-1\n",
    "#     return locs.astype(np.int32)\n",
    "\n",
    "def action(locs, board, hand_mng):\n",
    "    global graped_box, selected_box\n",
    "    \n",
    "    x, y = hand_mng.locs[8]\n",
    "    if hand_mng.state[1] == 1: # 클릭했을때\n",
    "        if board[y, x]:\n",
    "            box = box_obj[board[y, x]-1]\n",
    "            if box.editable:\n",
    "                selected_box = box\n",
    "            graped_box = box\n",
    "        else:\n",
    "            selected_box = None\n",
    "    elif hand_mng.state[1] == 2: # 드래그중일때\n",
    "        if graped_box and graped_box.editable:\n",
    "            graped_box.xywh[:2] = [x,y]\n",
    "    else:\n",
    "        graped_box = None\n",
    "\n",
    "# state = [0] * 4\n",
    "key_locs = [(900,100), (1020,100), (1140,100), \n",
    "           (900,220), (1020,220), (1140,220), \n",
    "           (900,340), (1020,340), (1140,340), \n",
    "           (900,460), (1020,460), (1140,460), ]\n",
    "key_text = ['1','2','3','4','5','6','7','8','9','*','0','#',]\n",
    "temp_box1 = BoxObject((110,110,200,200), text='box1', editable=True) # xywh\n",
    "temp_box2 = BoxObject((330,110,200,200), text='', editable=True) # xywh\n",
    "key_boxes = [BoxObject((x,y,100,100), text=n, editable=False) for (x,y),n in zip(key_locs,key_text)]\n",
    "box_obj = [temp_box1, temp_box2]\n",
    "box_obj.extend(key_boxes)\n",
    "selected_box = None\n",
    "graped_box = None\n",
    "\n",
    "right_hand = HandManager('Right')\n",
    "left_hand = HandManager('Left')\n",
    "manager_dict = {'Right':right_hand, 'Left':left_hand}\n",
    "\n",
    "cap = cv2.VideoCapture('http://192.168.0.8:8080/video')\n",
    "with mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            # If loading a video, use 'break' instead of 'continue'.\n",
    "            break\n",
    "            \n",
    "        image = cv2.flip(image, 1)\n",
    "        results = img_process(image)\n",
    "        tmp = image.copy()\n",
    "        \n",
    "        board = np.zeros((HEIGHT,WIDTH), dtype=np.int8)\n",
    "        for i, box in enumerate(box_obj, start=1):\n",
    "            box.draw(tmp)\n",
    "            xyxy = xywh_to_xyxy(box.xywh)\n",
    "            x1,y1,x2,y2 = np.clip(xyxy, 0, WIDTH)\n",
    "            board[y1:y2,x1:x2] = i\n",
    "        \n",
    "        cv2.addWeighted(tmp, 0.5, image, 0.5, 0, image)\n",
    "            \n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        if results.multi_hand_landmarks:\n",
    "            left_right = list(map(lambda x:x.classification[0].label, results.multi_handedness))\n",
    "            if len(left_right)==1 and left_right[0]=='Right':\n",
    "                hand_landmarks = results.multi_hand_landmarks[0]\n",
    "                mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS,)\n",
    "                right_hand.update(hand_landmarks.landmark)\n",
    "        \n",
    "                action(right_hand.locs, board, right_hand)\n",
    "                if selected_box and graped_box and not graped_box.editable and right_hand.state[1]==1:\n",
    "                    selected_box.text += graped_box.text\n",
    "            \n",
    "                \n",
    "                print('click mode')\n",
    "                    \n",
    "#             elif len(left_right)==2 and left_right[0]!=left_right[1]:\n",
    "#                 mp_drawing.draw_landmarks(image, results.multi_hand_landmarks[0], mp_hands.HAND_CONNECTIONS,)\n",
    "#                 mp_drawing.draw_landmarks(image, results.multi_hand_landmarks[1], mp_hands.HAND_CONNECTIONS,)\n",
    "#                 manager_dict[left_right[0]].update(results.multi_hand_landmarks[0].landmark)\n",
    "#                 manager_dict[left_right[1]].update(results.multi_hand_landmarks[1].landmark)\n",
    "                \n",
    "#                 if selected_box and key_state is None:\n",
    "                    \n",
    "                \n",
    "#                 if selected_box and key_state and right_hand.state==[0,0,0,0] and left_nad.state==[0,0,0,0]:\n",
    "#                     selected_box.text += key_state\n",
    "#                     key_state = None\n",
    "                    \n",
    "                \n",
    "#                 print('chat mode')\n",
    "            else:\n",
    "                print('None mode')\n",
    "                \n",
    "            print(right_hand)\n",
    "#             print(left_hand)\n",
    "            \n",
    "            print('graped_box:', graped_box)\n",
    "            print('selected_box:', selected_box)\n",
    "            \n",
    "                \n",
    "                    \n",
    "                \n",
    "        cv2.imshow('MediaPipe Hands', image)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "cv2.destroyAllWindows()   \n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4246cd75-5264-4e42-baaf-5cdc530642ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f114793e-fb0e-4891-874b-59ff2d5a830e",
   "metadata": {},
   "source": [
    "### AI Virtual Keyboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ce67f95c-3c6c-48ca-b249-e660a643a656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "click mode\n",
      "#####\n",
      "label : Right\n",
      "검지위치 : [195   0]\n",
      "dists : [0.25200308 0.40873044 0.52735985 0.63667838]\n",
      "state : [2, 2, 0, 0]\n",
      "graped_box: None\n",
      "selected_box: None\n"
     ]
    }
   ],
   "source": [
    "WIDTH, HEIGHT = 1280, 720\n",
    "\n",
    "def xyxy_to_xywh(xyxy):\n",
    "    center = (xyxy[2:] + xyxy[:2])//2\n",
    "    wh = xyxy[2:] - xyxy[:2]\n",
    "    return np.concatenate([center, wh], axis=-1)\n",
    "\n",
    "def xywh_to_xyxy(xywh):\n",
    "    xy1 = xywh[:2] - xywh[2:]//2\n",
    "    xy2 = xywh[:2] + xywh[2:]//2\n",
    "    return np.concatenate([xy1, xy2], axis=-1)\n",
    "\n",
    "def draw_text(img, text, box_xywh):\n",
    "    text_size = np.array(cv2.getTextSize(text, cv2.FONT_HERSHEY_COMPLEX, 1, 2)[0])\n",
    "    text_size[1] *= -1\n",
    "    text_xy1 = box_xywh[:2] - text_size//2\n",
    "    cv2.putText(img, text, text_xy1, cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 0), 2, cv2.LINE_AA, )\n",
    "    \n",
    "class BoxObject():\n",
    "    def __init__(self, xywh, color=(0, 0, 255), text='', editable=False):\n",
    "        self.xywh = np.array(xywh)\n",
    "        self.color = color\n",
    "        self.text = text\n",
    "        self.editable = editable\n",
    "        \n",
    "    def draw(self, img):\n",
    "        xyxy = xywh_to_xyxy(self.xywh)\n",
    "        cv2.rectangle(img, xyxy[:2], xyxy[2:], self.color, -1)\n",
    "        draw_text(img, self.text, self.xywh)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str((self.text, 'edit:%s'%self.editable))\n",
    "    \n",
    "class HandManager():\n",
    "    def __init__(self, label):\n",
    "        self.label = label\n",
    "        self.locs = [None]*21\n",
    "        self.std_len = None\n",
    "        self.dists = None\n",
    "        self.state = [0]*4 # 0-release, 1-click, 2-drag\n",
    "        \n",
    "    def update(self, marks):\n",
    "        locs = np.stack([to_numpy(mark) for mark in marks])\n",
    "        locs = np.clip(locs, 0, 1)\n",
    "        locs[:,0] *= WIDTH-1\n",
    "        locs[:,1] *= HEIGHT-1\n",
    "        self.locs = locs.astype(np.int32)\n",
    "        self.std_len = np.linalg.norm(locs[0] - locs[5])\n",
    "        self.dists = np.linalg.norm(locs[4] - locs[[8,12,16,20]], axis=1) / self.std_len\n",
    "\n",
    "        for i in range(4):\n",
    "            if not self.state[i] and self.dists[i] < 0.35: self.state[i] = 1\n",
    "            elif self.state[i] and 0.45 < self.dists[i]: self.state[i] = 0\n",
    "            elif self.state[i] == 1: self.state[i] = 2\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return '#####\\nlabel : {}\\n검지위치 : {}\\ndists : {}\\nstate : {}'.format(self.label, self.locs[8], self.dists, self.state)\n",
    "        \n",
    "        \n",
    "\n",
    "def img_process(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = hands.process(image)\n",
    "    return results\n",
    "\n",
    "def to_numpy(landmark):\n",
    "    return np.array([landmark.x, landmark.y])\n",
    "\n",
    "def action(locs, board, hand_mng):\n",
    "    global graped_box, selected_box\n",
    "    \n",
    "    x, y = hand_mng.locs[8]\n",
    "    if hand_mng.state[1] == 1: # 클릭했을때\n",
    "        if board[y, x]:\n",
    "            box = box_obj[board[y, x]-1]\n",
    "            if box.editable:\n",
    "                selected_box = box\n",
    "            graped_box = box\n",
    "        else:\n",
    "            selected_box = None\n",
    "    elif hand_mng.state[1] == 2: # 드래그중일때\n",
    "        if graped_box and graped_box.editable:\n",
    "            graped_box.xywh[:2] = [x,y]\n",
    "    else:\n",
    "        graped_box = None\n",
    "\n",
    "key_locs = [(900,100), (1010,100), (1120,100), \n",
    "           (900,210), (1010,210), (1120,210), \n",
    "           (900,320), (1010,320), (1120,320), \n",
    "           (900,430), (1010,430), (1120,430), ]\n",
    "key_text = ['1','2','3','4','5','6','7','8','9','*','0','#',]\n",
    "key_boxes = [BoxObject((x,y,100,100), text=n, editable=False) for (x,y),n in zip(key_locs,key_text)]\n",
    "\n",
    "temp_box1 = BoxObject((110,110,200,200), text='box1', editable=True) # xywh\n",
    "temp_box2 = BoxObject((330,110,200,200), text='', editable=True) # xywh\n",
    "box_obj = [temp_box1, temp_box2]\n",
    "box_obj.extend(key_boxes)\n",
    "\n",
    "selected_box = None\n",
    "graped_box = None\n",
    "\n",
    "right_hand = HandManager('Right')\n",
    "left_hand = HandManager('Left')\n",
    "manager_dict = {'Right':right_hand, 'Left':left_hand}\n",
    "\n",
    "cap = cv2.VideoCapture('http://192.168.0.8:8080/video')\n",
    "with mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            # If loading a video, use 'break' instead of 'continue'.\n",
    "            break\n",
    "            \n",
    "        image = cv2.flip(image, 1)\n",
    "        results = img_process(image)\n",
    "        tmp = image.copy()\n",
    "        \n",
    "        board = np.zeros((HEIGHT,WIDTH), dtype=np.int8)\n",
    "        for i, box in enumerate(box_obj, start=1):\n",
    "            box.draw(tmp)\n",
    "            xyxy = xywh_to_xyxy(box.xywh)\n",
    "            x1,y1,x2,y2 = np.clip(xyxy, 0, WIDTH)\n",
    "            board[y1:y2,x1:x2] = i\n",
    "        \n",
    "        cv2.addWeighted(tmp, 0.5, image, 0.5, 0, image)\n",
    "            \n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        if results.multi_hand_landmarks:\n",
    "            left_right = list(map(lambda x:x.classification[0].label, results.multi_handedness))\n",
    "            if len(left_right)==1 and left_right[0]=='Right':\n",
    "                hand_landmarks = results.multi_hand_landmarks[0]\n",
    "                mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS,)\n",
    "                right_hand.update(hand_landmarks.landmark)\n",
    "        \n",
    "                action(right_hand.locs, board, right_hand)\n",
    "                if selected_box and graped_box and not graped_box.editable and right_hand.state[1]==1:\n",
    "                    selected_box.text += graped_box.text\n",
    "            \n",
    "                print('click mode')\n",
    "                    \n",
    "            else:\n",
    "                print('None mode')\n",
    "                \n",
    "            print(right_hand)\n",
    "            \n",
    "            print('graped_box:', graped_box)\n",
    "            print('selected_box:', selected_box)\n",
    "                    \n",
    "        cv2.imshow('MediaPipe Hands', image)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "cv2.destroyAllWindows()   \n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3c255e-8c93-4c70-8dd0-e5b9ea270c3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e64d8b-c96f-40db-b673-c69969f891a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666e0b39-86b8-44dd-a2d0-19459355124d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f655da-8031-4c5a-95c9-e8a8cf2d2d77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150074ee-f17c-4335-bfa9-3ff1eceea09e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aea91a4-44b1-4da7-a960-5594653e9be5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71bbef9-241b-4fb5-8df6-837c0ab6a9ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669401dd-889d-4cb3-a95a-8d6dcffe648a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf42537-3cc0-4630-b303-81a562317421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b86fd19-8e32-4b2f-9cec-161a57daaf21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc2ae75-375e-4552-9317-0e38a165ad4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_clip_dispatcher() missing 1 required positional argument: 'a_max'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27656/938076348.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0maa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mclip\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: _clip_dispatcher() missing 1 required positional argument: 'a_max'"
     ]
    }
   ],
   "source": [
    "aa = np.array([-1,1,2,-2])\n",
    "np.clip(aa, 0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1617749c-403e-4fea-bb7d-4aecd2013889",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.zeros((300,300,3), np.uint8)\n",
    "\n",
    "font = cv2.FONT_HERSHEY_COMPLEX\n",
    "# 매개변수\n",
    "# 1. 이미지\n",
    "# 2. 텍스트\n",
    "# 3. 텍스트를 작성할 좌표 위치\n",
    "# 4. 폰트\n",
    "# 5. 폰트 크기\n",
    "# 6. 색상\n",
    "# 7. 폰트 굵기\n",
    "# 8. 선의 종류 // 공식홈페이지에서 색상, 두께, 선, 종류 등과 같이 규칙적인 것을 잘 보도록 cv2.LINE_AA을 권장하고 있다.\n",
    "aa = cv2.putText(img,'Happy Coding',(30,150), font, 1,(0, 0, 255), 2, cv2.LINE_AA, )\n",
    "\n",
    "cv2.imshow('putText', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc2396dd-2521-4b16-bafe-39a8d349eaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.zeros((300,300,3), np.uint8)\n",
    "\n",
    "cv2.rectangle(img, (10, 50) , (100, 200), (0,0,255), -1)\n",
    "draw_text(img, 'test', [10,50,100,200])\n",
    "\n",
    "cv2.imshow('putText', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e8d268-457b-4dcb-8caf-fd30def84edc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "14b4d748-8427-4e48-aefd-01d552891917",
   "metadata": {},
   "outputs": [],
   "source": [
    "box = BoxObject((200,200,50,150), text='test')\n",
    "\n",
    "img = np.zeros((300,300,3), np.uint8)\n",
    "\n",
    "box.draw(img)\n",
    "\n",
    "cv2.imshow('putText', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1245a47-fe74-467e-b06b-2bec5f63fc34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbe311e-df19-4840-abbe-ee0106af8fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a29f13a1-e432-4928-9c1d-3948a4d84b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = image.copy()\n",
    "tmp = output.copy()\n",
    "cv2.rectangle(tmp, (100, 100), (200, 200), (0, 0, 255), -1)\n",
    "cv2.addWeighted(tmp, 0.5, output, 0.5, 0, output)\n",
    "\n",
    "cv2.imshow('asdf', output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "19cb0ab7-db45-4d7c-96e6-be46ded4bbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('MediaPipe Hands', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90af7336-05e8-42f7-85bd-5b0981f4f471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0ce625-2370-4dee-a7fa-e605bc9aae3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.getTextSize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b2902c14-f90c-4e23-8769-90e4b645dd24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index: 0\n",
       "score: 0.9999662041664124\n",
       "label: \"Left\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.multi_handedness[0].classification[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7eace44d-c6b1-4c11-b6da-dd03899dfdef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[index: 0\n",
       "score: 0.9999662041664124\n",
       "label: \"Left\"\n",
       "]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.multi_handedness[0].classification[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
